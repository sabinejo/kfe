{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from rtree import index\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GDELT column names\n",
    "col_names = {\n",
    "    'eventID_name' : 'GLOBALEVENTID',\n",
    "    'root_code_name' : 'EventRootCode',\n",
    "    'quad_class_name': 'QuadClass',\n",
    "    'geo_country_name' : 'SourceActorFull',\n",
    "    'geo_region_name' : 'ActionGeo_CountryCode',\n",
    "    'actor_name' : 'Actor1Type1Code',\n",
    "    'url_name' : 'SOURCEURL',\n",
    "    'goldstein_name' : 'GoldsteinScale',\n",
    "    'date_name' : 'SQLDATE',\n",
    "    'Actor1Code': 'Actor1Type1Code',\n",
    "    'Actor2Code': 'Actor1Type2Code',\n",
    "    'Actor3Code': 'Actor1Type3Code'\n",
    "}\n",
    "\n",
    "# to save files\n",
    "path = '/Users/sabine.a.joseph/Desktop/'\n",
    "\n",
    "# path to folder containing all raw GDELT data files\n",
    "pathGDELT = '/Users/sabine.a.joseph/Downloads/GDELT_raw/'\n",
    "all_files = glob.glob(pathGDELT + '*.csv')\n",
    "\n",
    "df_datestring_column_name = 'SQLDATE'\n",
    "dateformat = '%Y%m'\n",
    "\n",
    "# create aggregates: intially for each individual GDELT df\n",
    "aggregations = {\n",
    "    'protest' : {'protest_events': 'sum'},\n",
    "    'material_conflict' : {'material_conflict': 'sum'},\n",
    "    'rebellion' : {'rebellion_events': 'sum'},\n",
    "    'GoldsteinScale' : {\n",
    "    'gs_median': 'median',\n",
    "    'gs_min': lambda x: min(x),\n",
    "    'gs_max': lambda x: max(x)},\n",
    "    'AvgTone' : {\n",
    "    'at_median': 'median',\n",
    "    'at_min': lambda x: min(x),\n",
    "    'at_max': lambda x: max(x)},\n",
    "    'count_num_daily_events' : {'count_num_daily_events': 'sum'},\n",
    "    'NumMentions' : {'NumMentions': 'sum'},\n",
    "    'NumSources' : {'NumSources': 'sum'},\n",
    "    'NumArticles' : {'NumArticles': 'sum'}\n",
    "}\n",
    "\n",
    "# create aggregates: finally for the combined GDELT df\n",
    "full_GDELT_aggregations = {\n",
    "    'protest' : {'protest_events': 'sum'},\n",
    "    'material_conflict' : {'material_conflict': 'sum'},\n",
    "    'rebellion' : {'rebellion_events': 'sum'},\n",
    "    'gs_median' : {'gs_median': 'mean'},\n",
    "    'gs_min' : {'gs_min': 'mean'},\n",
    "    'gs_max' : {'gs_max': 'mean'},\n",
    "    'at_median' : {'at_median': 'mean'},\n",
    "    'at_min' : {'at_min': 'mean'},\n",
    "    'at_max' : {'at_max': 'mean'},\n",
    "    'count_num_daily_events' : {'count_num_daily_events': 'sum'},\n",
    "    'NumMentions' : {'NumMentions': 'sum'},\n",
    "    'NumSources' : {'NumSources': 'sum'},\n",
    "    'NumArticles' : {'NumArticles': 'sum'}\n",
    "}\n",
    "\n",
    "# geo-level aggregation switch: country vs grid\n",
    "country_code = 'ActionGeo_CountryCode'\n",
    "bbox = 'bbox'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_coordinate_format(df, colname_list):\n",
    "    for i in range(0, len(colname_list)):\n",
    "        df[colname_list[i]] = [(float(df[colname_list[i]][j][:5])) for j in range (0, len(df[colname_list[i]]))]\n",
    "    return df\n",
    "\n",
    "def rtree_index_to_bbox_column(df_lon_col, df_lat_col):    \n",
    "    idx = index.Index()\n",
    "    # create rtree index, contains all bounding boxes\n",
    "    for i in range(0, len(df_grid.id)):\n",
    "        # if interleaved is True: xmin, ymin, xmax, ymax\n",
    "        idx.insert(i, (df_grid.xmin[i], df_grid.ymin[i], df_grid.xmax[i], df_grid.ymax[i]))\n",
    "    \n",
    "    # retrieve intersection idx for each coordinate pair\n",
    "    return [(list(idx.intersection((float(df_lon_col[i]), float(df_lat_col[i]), \n",
    "                                    float(df_lon_col[i]), float(df_lat_col[i])))))[0]\n",
    "            if math.isnan(df_lat_col[i]) is False and (list(idx.intersection((float(df_lon_col[i]), float(df_lat_col[i]), \n",
    "                                                                          float(df_lon_col[i]), float(df_lat_col[i])))))\n",
    "            else np.nan for i in range (0, df.shape[0])]\n",
    "\n",
    "# url and event ID duplicate removal\n",
    "# create new columns for protest, material conflict, rebellion, radicalism\n",
    "# cast Goldstein to float\n",
    "def EoI_columns(df, col_name_dict):\n",
    "    # max eventid for each url \n",
    "    if col_name_dict['url_name'] and col_name_dict['eventID_name'] is not None: \n",
    "        gdelt_max_id = df.groupby(col_name_dict['url_name'])[col_name_dict['eventID_name']].max()\n",
    "        # keep only max ids to remove duplicates\n",
    "        df = df[df[col_name_dict['eventID_name']].isin(gdelt_max_id)]\n",
    "    if col_name_dict['root_code_name'] is not None: \n",
    "        df['protest'] = np.where(df[col_name_dict['root_code_name']]==14, 1, 0)\n",
    "    if col_name_dict['quad_class_name'] is not None:\n",
    "        df['material_conflict'] = np.where(df[col_name_dict['quad_class_name']]==int(4), 1, 0)   \n",
    "    if col_name_dict['actor_name'] is not None: \n",
    "        df['rebellion'] = np.where(df[col_name_dict['actor_name']].isin(['REB','SEP','INS']), 1, 0)\n",
    "    if col_name_dict['Actor1Code'] and col_name_dict['Actor2Code'] and col_name_dict['Actor3Code'] is not None: \n",
    "        df['radicalism'] = np.where(np.logical_or.reduce((df[col_name_dict['Actor1Code']]=='RAD',\n",
    "                                                          df[col_name_dict['Actor2Code']]=='RAD',\n",
    "                                                          df[col_name_dict['Actor3Code']]=='RAD')),1, 0)\n",
    "    if 'goldstein_name' in col_name_dict:\n",
    "        df['GoldsteinScale'] = df[col_name_dict['goldstein_name']].apply(lambda x : float(x))\n",
    "    return df\n",
    "\n",
    "# save raw df\n",
    "def df_to_csv(df, path, filename):\n",
    "    df.to_csv(path + filename)\n",
    "\n",
    "def str_to_datetime(col_name, dateformat):\n",
    "    return [datetime.strptime(str(df[col_name][i]), dateformat) for i in range(0, df.shape[0]) if i is not None] \n",
    "\n",
    "# aggregate per country / bbox and month\n",
    "# index needs to be datetime\n",
    "# enter country_col_name as geo-switch: takes country code or bbox\n",
    "def agg_by_geo_by_month(df, agg_dict, country_col_name):\n",
    "    agg_df = df.groupby([df.index, country_col_name]).agg(agg_dict)\n",
    "    agg_df = agg_df.reset_index()\n",
    "    agg_df.columns = agg_df.columns.get_level_values(0)\n",
    "    return agg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sabine.a.joseph/Downloads/GDELT_raw/gdelt_20140101_20140131.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sabine.a.joseph/Downloads/GDELT_raw/gdelt_20140201_20140228.csv\n",
      "/Users/sabine.a.joseph/Downloads/GDELT_raw/gdelt_20140301_20140331.csv\n"
     ]
    }
   ],
   "source": [
    "# get and format gridcell data\n",
    "df_grid = pd.read_csv('/Users/sabine.a.joseph/Desktop/Gridcells_with_countryinfo.csv', sep = ';')\n",
    "df_grid = correct_coordinate_format(df_grid, ['xmin', 'xmax', 'ymin', 'ymax'])\n",
    "    \n",
    "for file in all_files:\n",
    "    print file\n",
    "    df = pd.read_csv(file)\n",
    "    df['bbox'] = rtree_index_to_bbox_column(df.Actor1Geo_Long, df.Actor1Geo_Lat)\n",
    "    \n",
    "    df.QuadClass = [int(df.QuadClass[i]) for i in range(0, df.shape[0])]\n",
    "    df.EventRootCode = [int(df.EventRootCode[i]) for i in range(0, df.shape[0])]\n",
    "    df = EoI_columns(df, col_names)\n",
    "    \n",
    "    # save raw data enriched with bbox labels\n",
    "    csv_name = 'GDELT_1Mo' + file[49:70]\n",
    "    df_to_csv(df, path, csv_name) \n",
    "\n",
    "    # date column to datetime index\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.SQLDATE = [str(df.SQLDATE[i])[:-2] for i in range (0, len(df.SQLDATE)) if i is not None]\n",
    "\n",
    "    df[df_datestring_column_name] = str_to_datetime(df_datestring_column_name, dateformat)\n",
    "    df.index = df[df_datestring_column_name]\n",
    "\n",
    "    df['count_num_daily_events'] = 1 \n",
    "    agg_df = agg_by_geo_by_month(df, aggregations, country_code) # or 'bbox' for grid level aggregation\n",
    "\n",
    "    # rename columns\n",
    "    agg_df.columns = ['SQLDATE', country_code, 'material_conflict', 'protest', 'gs_median', 'gs_min', \n",
    "                      'gs_max', 'NumSources', 'NumMentions', 'at_median', 'at_min', 'at_max', \n",
    "                      'count_num_daily_events', 'NumArticles', 'rebellion']\n",
    "\n",
    "    # save df to csv\n",
    "    if bbox in agg_df.columns:\n",
    "        csv_name = 'GDELT_agg/GDELT_1Mo_agg_subset_BBOX' + file[49:70]\n",
    "    else:\n",
    "        csv_name = 'GDELT_agg/GDELT_1Mo_agg_subset_COUNTRY' + file[49:70]\n",
    "    df_to_csv(agg_df, path, csv_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to folder containing aggregated raw GDELT data files\n",
    "pathGDELT_agg = '/Users/sabine.a.joseph/Desktop/GDELT_agg/'\n",
    "all_agg_files = glob.glob(pathGDELT_agg + '*.csv')\n",
    "\n",
    "def concat_dfs(pathGDELT_agg, all_agg_files):\n",
    "    for i in range(0, len(all_agg_files)):\n",
    "        if i == 0: #create initial df on first loop iteration\n",
    "            df = pd.read_csv(all_agg_files[i])\n",
    "        else: #concatenate df on each iteration\n",
    "            df = pd.concat([df, pd.read_csv(all_agg_files[i])]) \n",
    "\n",
    "    return df.reset_index(drop = True)\n",
    "\n",
    "full_GDELT_df = concat_dfs(pathGDELT_agg, all_agg_files)\n",
    "del full_GDELT_df['Unnamed: 0']\n",
    "\n",
    "full_agg_GDELT_df = agg_by_geo_by_month(full_GDELT_df, full_GDELT_aggregations, 'ActionGeo_CountryCode')\n",
    "df_to_csv(full_agg_GDELT_df, path, 'full_GDELT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
