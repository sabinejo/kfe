{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import lxml.html\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read excel with country names and codes\n",
    "# return list with country codes relevant for UCDP\n",
    "country_code_pathfile = '/Users/sabinejoseph/Downloads/kfe-sabinejo-patch-1/Input/Country_codes_NAMO.xlsx'\n",
    "country_code_column_name = 'Country_3'\n",
    "sheet = 'Sheet1'\n",
    "\n",
    "def country_codes_from_excel(country_codes, sheet_num, column_name):\n",
    "    countries = pd.ExcelFile(country_codes)\n",
    "    countries = countries.parse(sheet_num)\n",
    "    return list(countries[column_name]) # UCDP uses Gleditsch and Ward country codes\n",
    "\n",
    "CC3 = country_codes_from_excel(country_code_pathfile, sheet, country_code_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://phoenixdata.org/data'\n",
    "\n",
    "def connect_to_url_get_links(url):\n",
    "    connection = urllib.urlopen(url)\n",
    "    dom =  lxml.html.fromstring(connection.read())\n",
    "\n",
    "    links = []\n",
    "    for link in dom.xpath('//a/@href'): # select the url in href for all a tags(links)\n",
    "        links.append(link) #all download links in list\n",
    "    del links[0:4] \n",
    "    return links\n",
    "\n",
    "links = connect_to_url_get_links(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# downloads all files in dir #lengthy!!!\n",
    "DOWNLOADS_DIR = '/Users/sabinejoseph/Downloads/kfe-sabinejo-patch-1/Phoenix_data'\n",
    "\n",
    "def download_and_unzip_files(down_dir, links):\n",
    "    # For every line in the file\n",
    "    for url in links:\n",
    "        # Split on the rightmost / and take everything on the right side of that\n",
    "        name = url.rsplit('/', 1)[-1]\n",
    "\n",
    "        # Combine the name and the downloads directory to get the local filename\n",
    "        filename = os.path.join(down_dir, name)\n",
    "\n",
    "        # Download the file if it does not exist\n",
    "        if not os.path.isfile(filename):\n",
    "            urllib.urlretrieve(url, filename)\n",
    "\n",
    "    # unzip all files\n",
    "    filenames = []\n",
    "    for filename in os.listdir(down_dir):\n",
    "        if filename.endswith(\".txt.zip\"): \n",
    "            filenames.append(filename)\n",
    "            with zipfile.ZipFile(down_dir + '/' + filename) as zip_ref:\n",
    "                zip_ref.extractall(down_dir)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "download_and_unzip_files(DOWNLOADS_DIR, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load all data to df, for relevant region #lengthy!!!\n",
    "col_names = ('EventID', 'Date', 'Year', 'Month', 'Day', 'SourceActorFull', 'SourceActorEntity', \n",
    "             'SourceActorRole', 'SourceActorAttribute', 'TargetActorFull', 'TargetActorEntity', \n",
    "             'TargetActorRole', 'TargetActorAttribute', 'EventCode', 'EventRootCode', \n",
    "             'PentaClass', 'GoldsteinScore', 'Issues', 'Lat', 'Lon', 'LocationName', \n",
    "             'StateName', 'CountryCode', 'SentenceID', 'URLs', 'NewsSources')\n",
    "country_code_filter_col_name = 'SourceActorFull'\n",
    "\n",
    "def data_to_df(down_dir, col_names, country_codes, filter_col):\n",
    "    filenames = []\n",
    "    for filename in os.listdir(down_dir):\n",
    "        if filename.endswith(\".txt.zip\"): \n",
    "            filenames.append(filename)\n",
    "            \n",
    "    for i in range(0, len(filenames)):\n",
    "        if i == 0: #create initial df on first loop iteration\n",
    "            df = pd.read_table(down_dir + '/' + filenames[i][:-4], delim_whitespace=False, \n",
    "                               names=col_names)\n",
    "        else: #concatenate df on each iteration\n",
    "            df = pd.concat([df, pd.read_table(down_dir + '/' + filenames[i][:-4], delim_whitespace=False, \n",
    "                               names = col_names)]) \n",
    "            df = df[df[filter_col].isin(country_codes)] \n",
    "\n",
    "    df = df[df[filter_col].isin(country_codes)]  \n",
    "    df = df.reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "df = data_to_df(DOWNLOADS_DIR, col_names, CC3, country_code_filter_col_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save df as csv\n",
    "path = '/Users/sabinejoseph/Downloads/kfe-sabinejo-patch-1/'\n",
    "csv_name = 'Phoenix_NaMo_subset.csv'\n",
    "\n",
    "def df_to_csv(path, filename):\n",
    "    df.to_csv(path + filename)\n",
    "    \n",
    "df_to_csv(path, csv_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### if all already downloaded (previous steps), use the csv\n",
    "def csv_to_df(path, filename):\n",
    "    df = pd.read_csv(path + filename, sep = ',', low_memory=False)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df = csv_to_df(path, csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete not to be used columns\n",
    "# 'id' # only keep for data cleaning \n",
    "vars_to_del = ['EventID', 'Year', 'Month', 'Day', 'SourceActorEntity',\n",
    "           'SourceActorRole', 'SourceActorAttribute', 'TargetActorEntity', 'TargetActorRole', \n",
    "           'TargetActorAttribute', 'Issues', 'Lat', 'Lon', 'LocationName', 'StateName', 'CountryCode',\n",
    "           'SentenceID', 'URLs']\n",
    "  \n",
    "def del_columns_from_df(col_names):\n",
    "    for i in col_names:\n",
    "        del df[i]\n",
    "    return df\n",
    "\n",
    "df = del_columns_from_df(vars_to_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.Date = [str(df.Date[i])[:-2] for i in range (0, len(df.Date)) if i is not None]\n",
    "\n",
    "df_datestring_column_name = 'Date'\n",
    "dateformat = '%Y%m%d'\n",
    "\n",
    "def str_to_datetime(col_name, dateformat):\n",
    "    return [datetime.strptime(str(df[col_name][i]), dateformat) \n",
    "            for i in range(0, len(df[col_name])) if i is not None]\n",
    "\n",
    "df[df_datestring_column_name] = str_to_datetime(df_datestring_column_name, dateformat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter type of crisis \n",
    "# TargetActorFull # 1: state-based conflict # 2: non-state conflict # 3: one-sided violence\n",
    "df = df[df['PentaClass'].isin([1, 4])]\n",
    "\n",
    "# TargetActorEntity\n",
    "# EventCode\n",
    "# EventRootCode\n",
    "# NewsSources #sum individual newspapers 1 or two or more, count semicolons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grouping by date per country code\n",
    "new_format = '%Y-%m-%d'\n",
    "col_name_date = 'Date'\n",
    "col_name_country_codes = 'SourceActorFull'\n",
    "agg_col_names = ['GoldsteinScore']\n",
    "event_count_col_name = 'count_num_daily_events'\n",
    "\n",
    "def group_by_country_code_date_agg_sum(date, CC, col_name_list, ct_col_name, funct):\n",
    "# sum of death counts\n",
    "# count of events per day per country code\n",
    "    df[ct_col_name] = 1 \n",
    "    col_name_list.append(ct_col_name)\n",
    "    return df.groupby([date, CC]).agg(dict.fromkeys(col_name_list, funct))\n",
    "    # np.nanmedian\n",
    "    \n",
    "df_agg = group_by_country_code_date_agg_sum(col_name_date, col_name_country_codes, agg_col_names, event_count_col_name, sum).reset_index()\n",
    "df_agg.date_start = [df_agg[col_name_date][i].strftime(new_format) for i in range(0, len(df_agg.index)) if i is not None]\n",
    "\n",
    "df_agg_GS = group_by_country_code_date_agg_sum(col_name_date, col_name_country_codes, agg_col_names, event_count_col_name, np.nanmedian).reset_index()\n",
    "df_agg.GoldsteinScore = df_agg_GS.GoldsteinScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_name = 'Phoenix_NaMo_Agg_subset.csv'\n",
    "df_agg.to_csv(path + csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add column: event 0 - 1\n",
    "# relations between columns\n",
    "\n",
    "#df['TargetActorRole2'] = pd.factorize(df['TargetActorRole'])[0]\n",
    "#df['SourceActorFull2'] = pd.factorize(df['SourceActorFull'])[0]\n",
    "\n",
    "#df[['EventCode','EventRootCode']] = df[['EventCode','EventRootCode']].apply(pd.to_numeric, errors='ignore')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
